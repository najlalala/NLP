{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate\n!pip install sacrebleu","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-12-18T05:14:19.189093Z","iopub.execute_input":"2024-12-18T05:14:19.189483Z","iopub.status.idle":"2024-12-18T05:14:37.921087Z","shell.execute_reply.started":"2024-12-18T05:14:19.189444Z","shell.execute_reply":"2024-12-18T05:14:37.920217Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\nCollecting sacrebleu\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2024.5.15)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\nDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.0.0 sacrebleu-2.4.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Data Load","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\n# text_1 -> ind, text_2 -> mad\nmdr = load_dataset(\"indonlp/NusaX-MT\",name=\"ind-mad\") \nmdr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T05:14:37.923249Z","iopub.execute_input":"2024-12-18T05:14:37.923947Z","iopub.status.idle":"2024-12-18T05:15:32.118560Z","shell.execute_reply.started":"2024-12-18T05:14:37.923900Z","shell.execute_reply":"2024-12-18T05:15:32.117841Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"NusaX-MT.py:   0%|          | 0.00/5.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8c2c1edce634ed991eb42a187243fca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.64k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48188bd43bc640528b553d33d8ada118"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for indonlp/NusaX-MT contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/indonlp/NusaX-MT.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/935k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f64b47cc4b7c40029ad5c30cd5dbe6ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/184k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"343dde85895742f0b873ffa46b2cda72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/751k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f33889768bd34a8cb01e3e56bf3ec5b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa376871ec734161ac2ad6d3d0cd7c74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a51c81c2be37490d87b42be8a96ec5a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeb9a84e894e47a8b32d83f17f19fb85"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'text_1', 'text_2', 'text_1_lang', 'text_2_lang'],\n        num_rows: 500\n    })\n    validation: Dataset({\n        features: ['id', 'text_1', 'text_2', 'text_1_lang', 'text_2_lang'],\n        num_rows: 100\n    })\n    test: Dataset({\n        features: ['id', 'text_1', 'text_2', 'text_1_lang', 'text_2_lang'],\n        num_rows: 400\n    })\n})"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"train = mdr[\"train\"]\nval = mdr[\"validation\"]\ntest = mdr[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T05:15:32.119510Z","iopub.execute_input":"2024-12-18T05:15:32.119769Z","iopub.status.idle":"2024-12-18T05:15:32.123873Z","shell.execute_reply.started":"2024-12-18T05:15:32.119743Z","shell.execute_reply":"2024-12-18T05:15:32.122857Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from transformers.utils import move_cache\nmove_cache()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T05:15:32.126332Z","iopub.execute_input":"2024-12-18T05:15:32.126987Z","iopub.status.idle":"2024-12-18T05:15:35.328475Z","shell.execute_reply.started":"2024-12-18T05:15:32.126947Z","shell.execute_reply":"2024-12-18T05:15:35.327562Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c40bcb91c9c643a282e634a5d52cd8b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87759b5bf63c451f82378bc346de4edf"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# https://huggingface.co/indonlp/cendol-mt5-small-inst\ncheckpoint = \"indonlp/cendol-mt5-small-inst\" # GANTI MODELNYA\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T05:15:35.329437Z","iopub.execute_input":"2024-12-18T05:15:35.329834Z","iopub.status.idle":"2024-12-18T05:15:38.942331Z","shell.execute_reply.started":"2024-12-18T05:15:35.329806Z","shell.execute_reply":"2024-12-18T05:15:38.941539Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/330 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aae02ac7ba234e38ae23e9f94b02dd21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c78aee1453d84a3684e9ededfdac458f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9847a09d7a5647b39caf76ab4d013e96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7612fec86a8740e68e212922242c8963"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"prefix = \"terjemahkan dari Bahasa Indonesia ke Bahasa Madura: \" # nanti pas inference, perlu di append prefix nya!\n\ndef preprocess_function(examples):\n    # Menambahkan prefix dan melakukan lowercasing pada input\n    inputs = [prefix + example.lower() for example in examples[\"text_1\"]]  # optional: .lower() jika perlu\n    targets = [example.lower() for example in examples[\"text_2\"]]  # optional: .lower() jika perlu\n    \n    # Tokenisasi\n    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n    \n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T05:15:38.943450Z","iopub.execute_input":"2024-12-18T05:15:38.943894Z","iopub.status.idle":"2024-12-18T05:15:38.948922Z","shell.execute_reply.started":"2024-12-18T05:15:38.943865Z","shell.execute_reply":"2024-12-18T05:15:38.948134Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"tokenized_train = train.map(preprocess_function, batched=True)\ntokenized_val = val.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T05:15:38.950064Z","iopub.execute_input":"2024-12-18T05:15:38.950403Z","iopub.status.idle":"2024-12-18T05:15:39.164012Z","shell.execute_reply.started":"2024-12-18T05:15:38.950365Z","shell.execute_reply":"2024-12-18T05:15:39.163146Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3aab5683dedb41dca529d526e35ee434"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9000341117a43e3b15b0146a5e2051f"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T05:15:39.165067Z","iopub.execute_input":"2024-12-18T05:15:39.165347Z","iopub.status.idle":"2024-12-18T05:15:50.134134Z","shell.execute_reply.started":"2024-12-18T05:15:39.165321Z","shell.execute_reply":"2024-12-18T05:15:50.133196Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import evaluate\nimport numpy as np\n\nmetric = evaluate.load(\"sacrebleu\")\n\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n    return preds, labels\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Post-process texts\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n    # Compute BLEU score\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    result = {\"bleu\": result[\"score\"]}\n\n    # Calculate average generation length\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = round(np.mean(prediction_lens), 4)\n    \n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T05:15:50.135419Z","iopub.execute_input":"2024-12-18T05:15:50.136129Z","iopub.status.idle":"2024-12-18T05:15:52.506994Z","shell.execute_reply.started":"2024-12-18T05:15:50.136086Z","shell.execute_reply":"2024-12-18T05:15:52.506060Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0ef065705a4404fbdd611b11e70d2dd"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T05:15:52.509499Z","iopub.execute_input":"2024-12-18T05:15:52.510082Z","iopub.status.idle":"2024-12-18T05:16:23.540612Z","shell.execute_reply.started":"2024-12-18T05:15:52.510050Z","shell.execute_reply":"2024-12-18T05:16:23.539659Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/808 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eb9b0b1214b413fac713571f3b51ba4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.23G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bce190c72b154b6fac89cdfa964748a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2842e67c39444b79f5f193056462863"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"kacong_ali_cendol-mt5-small-inst_20\",\n    eval_strategy=\"epoch\",\n    learning_rate=3e-4,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=25,\n    predict_with_generate=True,\n    fp16=True,\n    generation_max_length=50\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\n\n#8e273a83f932e54c56230b4e303a2f335701ad7b","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T05:18:09.012048Z","iopub.execute_input":"2024-12-18T05:18:09.012908Z","iopub.status.idle":"2024-12-18T05:27:24.965160Z","shell.execute_reply.started":"2024-12-18T05:18:09.012870Z","shell.execute_reply":"2024-12-18T05:27:24.964461Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [800/800 09:14, Epoch 25/25]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.689046</td>\n      <td>21.424923</td>\n      <td>38.070000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.652359</td>\n      <td>23.095390</td>\n      <td>37.940000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.677738</td>\n      <td>22.705823</td>\n      <td>38.040000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>1.600047</td>\n      <td>22.877784</td>\n      <td>37.930000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>1.608194</td>\n      <td>23.277950</td>\n      <td>37.970000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>1.606061</td>\n      <td>23.593378</td>\n      <td>37.910000</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>1.615775</td>\n      <td>23.426078</td>\n      <td>37.970000</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>1.605466</td>\n      <td>24.004534</td>\n      <td>38.080000</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>No log</td>\n      <td>1.615053</td>\n      <td>23.548428</td>\n      <td>37.790000</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>No log</td>\n      <td>1.602554</td>\n      <td>23.654165</td>\n      <td>38.050000</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>No log</td>\n      <td>1.609340</td>\n      <td>23.956681</td>\n      <td>37.940000</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>No log</td>\n      <td>1.577597</td>\n      <td>23.561001</td>\n      <td>37.950000</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>No log</td>\n      <td>1.541909</td>\n      <td>24.729790</td>\n      <td>37.860000</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>No log</td>\n      <td>1.515738</td>\n      <td>25.095462</td>\n      <td>37.980000</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>No log</td>\n      <td>1.515483</td>\n      <td>24.928259</td>\n      <td>38.000000</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>1.031000</td>\n      <td>1.515502</td>\n      <td>24.899968</td>\n      <td>38.010000</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.031000</td>\n      <td>1.515529</td>\n      <td>24.899968</td>\n      <td>38.010000</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.031000</td>\n      <td>1.515436</td>\n      <td>24.891495</td>\n      <td>37.990000</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.031000</td>\n      <td>1.515456</td>\n      <td>24.899968</td>\n      <td>38.010000</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.031000</td>\n      <td>1.515386</td>\n      <td>24.899968</td>\n      <td>38.010000</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.031000</td>\n      <td>1.515390</td>\n      <td>24.891495</td>\n      <td>37.990000</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.031000</td>\n      <td>1.515426</td>\n      <td>24.899968</td>\n      <td>38.010000</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>1.031000</td>\n      <td>1.515292</td>\n      <td>24.891495</td>\n      <td>37.990000</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.031000</td>\n      <td>1.515261</td>\n      <td>24.899968</td>\n      <td>38.010000</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.031000</td>\n      <td>1.515323</td>\n      <td>24.899968</td>\n      <td>38.010000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=800, training_loss=0.9523292922973633, metrics={'train_runtime': 555.2788, 'train_samples_per_second': 22.511, 'train_steps_per_second': 1.441, 'total_flos': 1384828487270400.0, 'train_loss': 0.9523292922973633, 'epoch': 25.0})"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"tokenized_test = test.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T05:27:24.966503Z","iopub.execute_input":"2024-12-18T05:27:24.966770Z","iopub.status.idle":"2024-12-18T05:27:25.085060Z","shell.execute_reply.started":"2024-12-18T05:27:24.966743Z","shell.execute_reply":"2024-12-18T05:27:25.084257Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b591fb1511ab4478bcba703dd77b54e8"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"test_results = trainer.evaluate(tokenized_test)\nprint(\"Test BLEU score:\", test_results[\"eval_bleu\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T05:27:25.085978Z","iopub.execute_input":"2024-12-18T05:27:25.086256Z","iopub.status.idle":"2024-12-18T05:27:58.919061Z","shell.execute_reply.started":"2024-12-18T05:27:25.086199Z","shell.execute_reply":"2024-12-18T05:27:58.918147Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/25 00:27]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Test BLEU score: 24.446774380926154\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"test_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T05:27:58.921074Z","iopub.execute_input":"2024-12-18T05:27:58.921453Z","iopub.status.idle":"2024-12-18T05:27:58.928130Z","shell.execute_reply.started":"2024-12-18T05:27:58.921412Z","shell.execute_reply":"2024-12-18T05:27:58.927270Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 1.4462637901306152,\n 'eval_bleu': 24.446774380926154,\n 'eval_gen_len': 38.29,\n 'eval_runtime': 29.0173,\n 'eval_samples_per_second': 13.785,\n 'eval_steps_per_second': 0.862,\n 'epoch': 25.0}"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"## SAVE AND LOAD","metadata":{}},{"cell_type":"code","source":"# BUAT NGESAVE KE LOCAL!!!\nlocal_dir = \"cendol-mt5-small-inst\"\n\nmodel.save_pretrained(local_dir)\ntokenizer.save_pretrained(local_dir)\n\n# NANTI CARA NGE LOAD NYA GINI!!\n# from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\n# model = AutoModelForSeq2SeqLM.from_pretrained(local_dir)\n# tokenizer = AutoTokenizer.from_pretrained(local_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:03:08.337407Z","iopub.execute_input":"2024-11-18T14:03:08.337823Z","iopub.status.idle":"2024-11-18T14:03:11.029676Z","shell.execute_reply.started":"2024-11-18T14:03:08.337785Z","shell.execute_reply":"2024-11-18T14:03:11.028406Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T13:36:36.507867Z","iopub.execute_input":"2024-11-18T13:36:36.508162Z","iopub.status.idle":"2024-11-18T13:36:36.514978Z","shell.execute_reply.started":"2024-11-18T13:36:36.508117Z","shell.execute_reply":"2024-11-18T13:36:36.514094Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(local_dir)\ntokenizer = AutoTokenizer.from_pretrained(local_dir)\n\ndef translate_and_compare_samples(test_data, num_samples=5):\n    samples = random.sample(range(len(test_data['text_1'])), num_samples)\n    \n    for idx in samples:\n        source_text = test_data['text_1'][idx]\n        target_text = test_data['text_2'][idx]\n        text = f\"terjemahkan dari Bahasa Indonesia ke Bahasa Madura: {source_text}\"\n        inputs = tokenizer(text, return_tensors=\"pt\", max_length=128, truncation=True)\n        outputs = model.generate(**inputs, max_length=128, num_beams=4, early_stopping=True)\n        translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        print(f\"Sampel {idx + 1}\")\n        print(\"Source Text (Indonesia):\", source_text)\n        print(\"Translated Text (Madura):\", translated_text)\n        print(\"Target Text (Expected Madura):\", target_text)\n        print(\"=\" * 50)\n\ntranslate_and_compare_samples(test, num_samples=5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:03:41.151732Z","iopub.execute_input":"2024-11-18T14:03:41.152172Z","iopub.status.idle":"2024-11-18T14:04:08.591429Z","shell.execute_reply.started":"2024-11-18T14:03:41.152111Z","shell.execute_reply":"2024-11-18T14:04:08.590424Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(local_dir)\ntokenizer = AutoTokenizer.from_pretrained(local_dir)\n\ntext = \"terjemahkan dari Bahasa Indonesia ke Bahasa Madura: gimana kabarmu?\"\n\ninputs = tokenizer(text, return_tensors=\"pt\", max_length=128, truncation=True)\noutputs = model.generate(**inputs, max_length=128, num_beams=4, early_stopping=True)\n\ntranslated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(\"Translated text:\", translated_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:03:16.371044Z","iopub.execute_input":"2024-11-18T14:03:16.371532Z","iopub.status.idle":"2024-11-18T14:03:20.894448Z","shell.execute_reply.started":"2024-11-18T14:03:16.371490Z","shell.execute_reply":"2024-11-18T14:03:20.893490Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\n# Inisialisasi model dan tokenizer\nmodel = AutoModelForSeq2SeqLM.from_pretrained(local_dir)\ntokenizer = AutoTokenizer.from_pretrained(local_dir)\n\n# Teks masukan dalam bahasa Madura\ntext = \"terjemahkan dari Bahasa Madura ke Bahasa Indonesia: Semmak bik hotel engkok nginep, pera' ejeleni ajelen soko, ediye bennyak sarah pelean kakananna, kenengngan se leber, ben masenneng\"\n\n# Tokenisasi input\ninputs = tokenizer(text, return_tensors=\"pt\", max_length=128, truncation=True)\n\n# Generasi terjemahan\noutputs = model.generate(**inputs, max_length=128, num_beams=4, early_stopping=True)\n\n# Dekode hasil terjemahan\ntranslated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(\"Translated text:\", translated_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:07:02.045412Z","iopub.execute_input":"2024-11-18T14:07:02.045854Z","iopub.status.idle":"2024-11-18T14:07:08.989977Z","shell.execute_reply.started":"2024-11-18T14:07:02.045815Z","shell.execute_reply":"2024-11-18T14:07:08.988855Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import random\n# import pandas as pd\n# from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n# import sacrebleu\n\n# # Inisialisasi model dan tokenizer\n# model = AutoModelForSeq2SeqLM.from_pretrained(local_dir)\n# tokenizer = AutoTokenizer.from_pretrained(local_dir)\n\n# # Fungsi untuk menerjemahkan dan membandingkan hasil dengan skor BLEU\n# def translate_and_compare_samples(test_data, num_samples=100):\n#     # Ambil beberapa sampel acak dari data test\n#     samples = random.sample(range(len(test_data['text_1'])), num_samples)\n\n#     # List untuk menyimpan hasil yang akan dikonversi menjadi tabel\n#     results = []\n\n#     for idx in samples:\n#         source_text = test_data['text_1'][idx]\n#         target_text = test_data['text_2'][idx]\n#         text = f\"terjemahkan dari Bahasa Indonesia ke Bahasa Madura: {source_text}\"\n        \n#         # Tokenisasi dan terjemahan\n#         inputs = tokenizer(text, return_tensors=\"pt\", max_length=128, truncation=True)\n#         outputs = model.generate(**inputs, max_length=128, num_beams=4, early_stopping=True)\n        \n#         # Dekode hasil terjemahan\n#         translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        \n#         # Hitung skor BLEU\n#         bleu = sacrebleu.corpus_bleu([translated_text], [[target_text]]).score\n        \n#         # Tambahkan hasil ke list\n#         results.append({\n#             \"Source Text (Indonesia)\": source_text,\n#             \"Translated Text (Madura)\": translated_text,\n#             \"Target Text (Expected Madura)\": target_text,\n#             \"BLEU Score\": bleu\n#         })\n\n#     # Konversi hasil ke dalam DataFrame pandas\n#     df_results = pd.DataFrame(results)\n#     return df_results\n\n# # Panggil fungsi dan tampilkan hasil dalam bentuk tabel\n# df_results = translate_and_compare_samples(test, num_samples=100)\n# df_results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T13:37:18.654987Z","iopub.execute_input":"2024-11-18T13:37:18.655354Z","iopub.status.idle":"2024-11-18T13:39:26.252087Z","shell.execute_reply.started":"2024-11-18T13:37:18.655319Z","shell.execute_reply":"2024-11-18T13:39:26.245287Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df_results.to_csv(\"translation_results_full.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T13:39:26.252985Z","iopub.status.idle":"2024-11-18T13:39:26.253378Z","shell.execute_reply.started":"2024-11-18T13:39:26.253188Z","shell.execute_reply":"2024-11-18T13:39:26.253209Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}